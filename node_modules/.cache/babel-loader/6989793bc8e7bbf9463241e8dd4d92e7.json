{"ast":null,"code":"'use strict';\n\nconst util = require('util');\n\nconst crypto = require('crypto');\n\nconst fs = require('fs');\n\nconst Minipass = require('minipass');\n\nconst path = require('path');\n\nconst ssri = require('ssri');\n\nconst contentPath = require('./content/path');\n\nconst fixOwner = require('./util/fix-owner');\n\nconst hashToSegments = require('./util/hash-to-segments');\n\nconst indexV = require('../package.json')['cache-version'].index;\n\nconst appendFile = util.promisify(fs.appendFile);\nconst readFile = util.promisify(fs.readFile);\nconst readdir = util.promisify(fs.readdir);\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor(cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`);\n    this.code = 'ENOENT';\n    this.cache = cache;\n    this.key = key;\n  }\n\n};\nmodule.exports.insert = insert;\n\nfunction insert(cache, key, integrity, opts = {}) {\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  return fixOwner.mkdirfix(cache, path.dirname(bucket)).then(() => {\n    const stringified = JSON.stringify(entry); // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with this.\n\n    return appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n  }).then(() => fixOwner.chownr(cache, bucket)).catch(err => {\n    if (err.code === 'ENOENT') {\n      return undefined;\n    }\n\n    throw err; // There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }).then(() => {\n    return formatEntry(cache, entry);\n  });\n}\n\nmodule.exports.insert.sync = insertSync;\n\nfunction insertSync(cache, key, integrity, opts = {}) {\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket));\n  const stringified = JSON.stringify(entry);\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n\n  try {\n    fixOwner.chownr.sync(cache, bucket);\n  } catch (err) {\n    if (err.code !== 'ENOENT') {\n      throw err;\n    }\n  }\n\n  return formatEntry(cache, entry);\n}\n\nmodule.exports.find = find;\n\nfunction find(cache, key) {\n  const bucket = bucketPath(cache, key);\n  return bucketEntries(bucket).then(entries => {\n    return entries.reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  }).catch(err => {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  });\n}\n\nmodule.exports.find.sync = findSync;\n\nfunction findSync(cache, key) {\n  const bucket = bucketPath(cache, key);\n\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  }\n}\n\nmodule.exports.delete = del;\n\nfunction del(cache, key, opts) {\n  return insert(cache, key, null, opts);\n}\n\nmodule.exports.delete.sync = delSync;\n\nfunction delSync(cache, key, opts) {\n  return insertSync(cache, key, null, opts);\n}\n\nmodule.exports.lsStream = lsStream;\n\nfunction lsStream(cache) {\n  const indexDir = bucketDir(cache);\n  const stream = new Minipass({\n    objectMode: true\n  });\n  readdirOrEmpty(indexDir).then(buckets => Promise.all(buckets.map(bucket => {\n    const bucketPath = path.join(indexDir, bucket);\n    return readdirOrEmpty(bucketPath).then(subbuckets => Promise.all(subbuckets.map(subbucket => {\n      const subbucketPath = path.join(bucketPath, subbucket); // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n\n      return readdirOrEmpty(subbucketPath).then(entries => Promise.all(entries.map(entry => {\n        const entryPath = path.join(subbucketPath, entry);\n        return bucketEntries(entryPath).then(entries => // using a Map here prevents duplicate keys from\n        // showing up twice, I guess?\n        entries.reduce((acc, entry) => {\n          acc.set(entry.key, entry);\n          return acc;\n        }, new Map())).then(reduced => {\n          // reduced is a map of key => entry\n          for (const entry of reduced.values()) {\n            const formatted = formatEntry(cache, entry);\n\n            if (formatted) {\n              stream.write(formatted);\n            }\n          }\n        }).catch(err => {\n          if (err.code === 'ENOENT') {\n            return undefined;\n          }\n\n          throw err;\n        });\n      })));\n    })));\n  }))).then(() => stream.end(), err => stream.emit('error', err));\n  return stream;\n}\n\nmodule.exports.ls = ls;\n\nfunction ls(cache) {\n  return lsStream(cache).collect().then(entries => entries.reduce((acc, xs) => {\n    acc[xs.key] = xs;\n    return acc;\n  }, {}));\n}\n\nfunction bucketEntries(bucket, filter) {\n  return readFile(bucket, 'utf8').then(data => _bucketEntries(data, filter));\n}\n\nfunction bucketEntriesSync(bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\n\nfunction _bucketEntries(data, filter) {\n  const entries = [];\n  data.split('\\n').forEach(entry => {\n    if (!entry) {\n      return;\n    }\n\n    const pieces = entry.split('\\t');\n\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return;\n    }\n\n    let obj;\n\n    try {\n      obj = JSON.parse(pieces[1]);\n    } catch (e) {\n      // Entry is corrupted!\n      return;\n    }\n\n    if (obj) {\n      entries.push(obj);\n    }\n  });\n  return entries;\n}\n\nmodule.exports.bucketDir = bucketDir;\n\nfunction bucketDir(cache) {\n  return path.join(cache, `index-v${indexV}`);\n}\n\nmodule.exports.bucketPath = bucketPath;\n\nfunction bucketPath(cache, key) {\n  const hashed = hashKey(key);\n  return path.join.apply(path, [bucketDir(cache)].concat(hashToSegments(hashed)));\n}\n\nmodule.exports.hashKey = hashKey;\n\nfunction hashKey(key) {\n  return hash(key, 'sha256');\n}\n\nmodule.exports.hashEntry = hashEntry;\n\nfunction hashEntry(str) {\n  return hash(str, 'sha1');\n}\n\nfunction hash(str, digest) {\n  return crypto.createHash(digest).update(str).digest('hex');\n}\n\nfunction formatEntry(cache, entry) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity) {\n    return null;\n  }\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: contentPath(cache, entry.integrity),\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  };\n}\n\nfunction readdirOrEmpty(dir) {\n  return readdir(dir).catch(err => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') {\n      return [];\n    }\n\n    throw err;\n  });\n}","map":{"version":3,"sources":["/Users/kaelen/nsc-mds/node_modules/npm/node_modules/cacache/lib/entry-index.js"],"names":["util","require","crypto","fs","Minipass","path","ssri","contentPath","fixOwner","hashToSegments","indexV","index","appendFile","promisify","readFile","readdir","module","exports","NotFoundError","Error","constructor","cache","key","code","insert","integrity","opts","metadata","size","bucket","bucketPath","entry","stringify","time","Date","now","mkdirfix","dirname","then","stringified","JSON","hashEntry","chownr","catch","err","undefined","formatEntry","sync","insertSync","appendFileSync","find","bucketEntries","entries","reduce","latest","next","findSync","bucketEntriesSync","delete","del","delSync","lsStream","indexDir","bucketDir","stream","objectMode","readdirOrEmpty","buckets","Promise","all","map","join","subbuckets","subbucket","subbucketPath","entryPath","acc","set","Map","reduced","values","formatted","write","end","emit","ls","collect","xs","filter","data","_bucketEntries","readFileSync","split","forEach","pieces","obj","parse","e","push","hashed","hashKey","apply","concat","hash","str","digest","createHash","update","dir"],"mappings":"AAAA;;AAEA,MAAMA,IAAI,GAAGC,OAAO,CAAC,MAAD,CAApB;;AAEA,MAAMC,MAAM,GAAGD,OAAO,CAAC,QAAD,CAAtB;;AACA,MAAME,EAAE,GAAGF,OAAO,CAAC,IAAD,CAAlB;;AACA,MAAMG,QAAQ,GAAGH,OAAO,CAAC,UAAD,CAAxB;;AACA,MAAMI,IAAI,GAAGJ,OAAO,CAAC,MAAD,CAApB;;AACA,MAAMK,IAAI,GAAGL,OAAO,CAAC,MAAD,CAApB;;AACA,MAAMM,WAAW,GAAGN,OAAO,CAAC,gBAAD,CAA3B;;AACA,MAAMO,QAAQ,GAAGP,OAAO,CAAC,kBAAD,CAAxB;;AACA,MAAMQ,cAAc,GAAGR,OAAO,CAAC,yBAAD,CAA9B;;AACA,MAAMS,MAAM,GAAGT,OAAO,CAAC,iBAAD,CAAP,CAA2B,eAA3B,EAA4CU,KAA3D;;AAEA,MAAMC,UAAU,GAAGZ,IAAI,CAACa,SAAL,CAAeV,EAAE,CAACS,UAAlB,CAAnB;AACA,MAAME,QAAQ,GAAGd,IAAI,CAACa,SAAL,CAAeV,EAAE,CAACW,QAAlB,CAAjB;AACA,MAAMC,OAAO,GAAGf,IAAI,CAACa,SAAL,CAAeV,EAAE,CAACY,OAAlB,CAAhB;AAEAC,MAAM,CAACC,OAAP,CAAeC,aAAf,GAA+B,MAAMA,aAAN,SAA4BC,KAA5B,CAAkC;AAC/DC,EAAAA,WAAW,CAAEC,KAAF,EAASC,GAAT,EAAc;AACvB,UAAO,sBAAqBA,GAAI,aAAYD,KAAM,EAAlD;AACA,SAAKE,IAAL,GAAY,QAAZ;AACA,SAAKF,KAAL,GAAaA,KAAb;AACA,SAAKC,GAAL,GAAWA,GAAX;AACD;;AAN8D,CAAjE;AASAN,MAAM,CAACC,OAAP,CAAeO,MAAf,GAAwBA,MAAxB;;AAEA,SAASA,MAAT,CAAiBH,KAAjB,EAAwBC,GAAxB,EAA6BG,SAA7B,EAAwCC,IAAI,GAAG,EAA/C,EAAmD;AACjD,QAAM;AAAEC,IAAAA,QAAF;AAAYC,IAAAA;AAAZ,MAAqBF,IAA3B;AACA,QAAMG,MAAM,GAAGC,UAAU,CAACT,KAAD,EAAQC,GAAR,CAAzB;AACA,QAAMS,KAAK,GAAG;AACZT,IAAAA,GADY;AAEZG,IAAAA,SAAS,EAAEA,SAAS,IAAInB,IAAI,CAAC0B,SAAL,CAAeP,SAAf,CAFZ;AAGZQ,IAAAA,IAAI,EAAEC,IAAI,CAACC,GAAL,EAHM;AAIZP,IAAAA,IAJY;AAKZD,IAAAA;AALY,GAAd;AAOA,SAAOnB,QAAQ,CACZ4B,QADI,CACKf,KADL,EACYhB,IAAI,CAACgC,OAAL,CAAaR,MAAb,CADZ,EAEJS,IAFI,CAEC,MAAM;AACV,UAAMC,WAAW,GAAGC,IAAI,CAACR,SAAL,CAAeD,KAAf,CAApB,CADU,CAEV;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,WAAOnB,UAAU,CAACiB,MAAD,EAAU,KAAIY,SAAS,CAACF,WAAD,CAAc,KAAIA,WAAY,EAArD,CAAjB;AACD,GAZI,EAaJD,IAbI,CAaC,MAAM9B,QAAQ,CAACkC,MAAT,CAAgBrB,KAAhB,EAAuBQ,MAAvB,CAbP,EAcJc,KAdI,CAcGC,GAAD,IAAS;AACd,QAAIA,GAAG,CAACrB,IAAJ,KAAa,QAAjB,EAA2B;AACzB,aAAOsB,SAAP;AACD;;AACD,UAAMD,GAAN,CAJc,CAKd;AACA;AACA;AACA;AACA;AACD,GAxBI,EAyBJN,IAzBI,CAyBC,MAAM;AACV,WAAOQ,WAAW,CAACzB,KAAD,EAAQU,KAAR,CAAlB;AACD,GA3BI,CAAP;AA4BD;;AAEDf,MAAM,CAACC,OAAP,CAAeO,MAAf,CAAsBuB,IAAtB,GAA6BC,UAA7B;;AAEA,SAASA,UAAT,CAAqB3B,KAArB,EAA4BC,GAA5B,EAAiCG,SAAjC,EAA4CC,IAAI,GAAG,EAAnD,EAAuD;AACrD,QAAM;AAAEC,IAAAA,QAAF;AAAYC,IAAAA;AAAZ,MAAqBF,IAA3B;AACA,QAAMG,MAAM,GAAGC,UAAU,CAACT,KAAD,EAAQC,GAAR,CAAzB;AACA,QAAMS,KAAK,GAAG;AACZT,IAAAA,GADY;AAEZG,IAAAA,SAAS,EAAEA,SAAS,IAAInB,IAAI,CAAC0B,SAAL,CAAeP,SAAf,CAFZ;AAGZQ,IAAAA,IAAI,EAAEC,IAAI,CAACC,GAAL,EAHM;AAIZP,IAAAA,IAJY;AAKZD,IAAAA;AALY,GAAd;AAOAnB,EAAAA,QAAQ,CAAC4B,QAAT,CAAkBW,IAAlB,CAAuB1B,KAAvB,EAA8BhB,IAAI,CAACgC,OAAL,CAAaR,MAAb,CAA9B;AACA,QAAMU,WAAW,GAAGC,IAAI,CAACR,SAAL,CAAeD,KAAf,CAApB;AACA5B,EAAAA,EAAE,CAAC8C,cAAH,CAAkBpB,MAAlB,EAA2B,KAAIY,SAAS,CAACF,WAAD,CAAc,KAAIA,WAAY,EAAtE;;AACA,MAAI;AACF/B,IAAAA,QAAQ,CAACkC,MAAT,CAAgBK,IAAhB,CAAqB1B,KAArB,EAA4BQ,MAA5B;AACD,GAFD,CAEE,OAAOe,GAAP,EAAY;AACZ,QAAIA,GAAG,CAACrB,IAAJ,KAAa,QAAjB,EAA2B;AACzB,YAAMqB,GAAN;AACD;AACF;;AACD,SAAOE,WAAW,CAACzB,KAAD,EAAQU,KAAR,CAAlB;AACD;;AAEDf,MAAM,CAACC,OAAP,CAAeiC,IAAf,GAAsBA,IAAtB;;AAEA,SAASA,IAAT,CAAe7B,KAAf,EAAsBC,GAAtB,EAA2B;AACzB,QAAMO,MAAM,GAAGC,UAAU,CAACT,KAAD,EAAQC,GAAR,CAAzB;AACA,SAAO6B,aAAa,CAACtB,MAAD,CAAb,CACJS,IADI,CACEc,OAAD,IAAa;AACjB,WAAOA,OAAO,CAACC,MAAR,CAAe,CAACC,MAAD,EAASC,IAAT,KAAkB;AACtC,UAAIA,IAAI,IAAIA,IAAI,CAACjC,GAAL,KAAaA,GAAzB,EAA8B;AAC5B,eAAOwB,WAAW,CAACzB,KAAD,EAAQkC,IAAR,CAAlB;AACD,OAFD,MAEO;AACL,eAAOD,MAAP;AACD;AACF,KANM,EAMJ,IANI,CAAP;AAOD,GATI,EAUJX,KAVI,CAUGC,GAAD,IAAS;AACd,QAAIA,GAAG,CAACrB,IAAJ,KAAa,QAAjB,EAA2B;AACzB,aAAO,IAAP;AACD,KAFD,MAEO;AACL,YAAMqB,GAAN;AACD;AACF,GAhBI,CAAP;AAiBD;;AAED5B,MAAM,CAACC,OAAP,CAAeiC,IAAf,CAAoBH,IAApB,GAA2BS,QAA3B;;AAEA,SAASA,QAAT,CAAmBnC,KAAnB,EAA0BC,GAA1B,EAA+B;AAC7B,QAAMO,MAAM,GAAGC,UAAU,CAACT,KAAD,EAAQC,GAAR,CAAzB;;AACA,MAAI;AACF,WAAOmC,iBAAiB,CAAC5B,MAAD,CAAjB,CAA0BwB,MAA1B,CAAiC,CAACC,MAAD,EAASC,IAAT,KAAkB;AACxD,UAAIA,IAAI,IAAIA,IAAI,CAACjC,GAAL,KAAaA,GAAzB,EAA8B;AAC5B,eAAOwB,WAAW,CAACzB,KAAD,EAAQkC,IAAR,CAAlB;AACD,OAFD,MAEO;AACL,eAAOD,MAAP;AACD;AACF,KANM,EAMJ,IANI,CAAP;AAOD,GARD,CAQE,OAAOV,GAAP,EAAY;AACZ,QAAIA,GAAG,CAACrB,IAAJ,KAAa,QAAjB,EAA2B;AACzB,aAAO,IAAP;AACD,KAFD,MAEO;AACL,YAAMqB,GAAN;AACD;AACF;AACF;;AAED5B,MAAM,CAACC,OAAP,CAAeyC,MAAf,GAAwBC,GAAxB;;AAEA,SAASA,GAAT,CAActC,KAAd,EAAqBC,GAArB,EAA0BI,IAA1B,EAAgC;AAC9B,SAAOF,MAAM,CAACH,KAAD,EAAQC,GAAR,EAAa,IAAb,EAAmBI,IAAnB,CAAb;AACD;;AAEDV,MAAM,CAACC,OAAP,CAAeyC,MAAf,CAAsBX,IAAtB,GAA6Ba,OAA7B;;AAEA,SAASA,OAAT,CAAkBvC,KAAlB,EAAyBC,GAAzB,EAA8BI,IAA9B,EAAoC;AAClC,SAAOsB,UAAU,CAAC3B,KAAD,EAAQC,GAAR,EAAa,IAAb,EAAmBI,IAAnB,CAAjB;AACD;;AAEDV,MAAM,CAACC,OAAP,CAAe4C,QAAf,GAA0BA,QAA1B;;AAEA,SAASA,QAAT,CAAmBxC,KAAnB,EAA0B;AACxB,QAAMyC,QAAQ,GAAGC,SAAS,CAAC1C,KAAD,CAA1B;AACA,QAAM2C,MAAM,GAAG,IAAI5D,QAAJ,CAAa;AAAE6D,IAAAA,UAAU,EAAE;AAAd,GAAb,CAAf;AAEAC,EAAAA,cAAc,CAACJ,QAAD,CAAd,CAAyBxB,IAAzB,CAA8B6B,OAAO,IAAIC,OAAO,CAACC,GAAR,CACvCF,OAAO,CAACG,GAAR,CAAYzC,MAAM,IAAI;AACpB,UAAMC,UAAU,GAAGzB,IAAI,CAACkE,IAAL,CAAUT,QAAV,EAAoBjC,MAApB,CAAnB;AACA,WAAOqC,cAAc,CAACpC,UAAD,CAAd,CAA2BQ,IAA3B,CAAgCkC,UAAU,IAAIJ,OAAO,CAACC,GAAR,CACnDG,UAAU,CAACF,GAAX,CAAeG,SAAS,IAAI;AAC1B,YAAMC,aAAa,GAAGrE,IAAI,CAACkE,IAAL,CAAUzC,UAAV,EAAsB2C,SAAtB,CAAtB,CAD0B,CAG1B;;AACA,aAAOP,cAAc,CAACQ,aAAD,CAAd,CAA8BpC,IAA9B,CAAmCc,OAAO,IAAIgB,OAAO,CAACC,GAAR,CACnDjB,OAAO,CAACkB,GAAR,CAAYvC,KAAK,IAAI;AACnB,cAAM4C,SAAS,GAAGtE,IAAI,CAACkE,IAAL,CAAUG,aAAV,EAAyB3C,KAAzB,CAAlB;AACA,eAAOoB,aAAa,CAACwB,SAAD,CAAb,CAAyBrC,IAAzB,CAA8Bc,OAAO,IAC1C;AACA;AACAA,QAAAA,OAAO,CAACC,MAAR,CAAe,CAACuB,GAAD,EAAM7C,KAAN,KAAgB;AAC7B6C,UAAAA,GAAG,CAACC,GAAJ,CAAQ9C,KAAK,CAACT,GAAd,EAAmBS,KAAnB;AACA,iBAAO6C,GAAP;AACD,SAHD,EAGG,IAAIE,GAAJ,EAHH,CAHK,EAOLxC,IAPK,CAOAyC,OAAO,IAAI;AAChB;AACA,eAAK,MAAMhD,KAAX,IAAoBgD,OAAO,CAACC,MAAR,EAApB,EAAsC;AACpC,kBAAMC,SAAS,GAAGnC,WAAW,CAACzB,KAAD,EAAQU,KAAR,CAA7B;;AACA,gBAAIkD,SAAJ,EAAe;AACbjB,cAAAA,MAAM,CAACkB,KAAP,CAAaD,SAAb;AACD;AACF;AACF,SAfM,EAeJtC,KAfI,CAeEC,GAAG,IAAI;AACd,cAAIA,GAAG,CAACrB,IAAJ,KAAa,QAAjB,EAA2B;AAAE,mBAAOsB,SAAP;AAAkB;;AAC/C,gBAAMD,GAAN;AACD,SAlBM,CAAP;AAmBD,OArBD,CADmD,CAA9C,CAAP;AAwBD,KA5BD,CADmD,CAA9C,CAAP;AA+BD,GAjCD,CADuC,CAAzC,EAoCGN,IApCH,CAqCI,MAAM0B,MAAM,CAACmB,GAAP,EArCV,EAsCIvC,GAAG,IAAIoB,MAAM,CAACoB,IAAP,CAAY,OAAZ,EAAqBxC,GAArB,CAtCX;AAyCA,SAAOoB,MAAP;AACD;;AAEDhD,MAAM,CAACC,OAAP,CAAeoE,EAAf,GAAoBA,EAApB;;AAEA,SAASA,EAAT,CAAahE,KAAb,EAAoB;AAClB,SAAOwC,QAAQ,CAACxC,KAAD,CAAR,CAAgBiE,OAAhB,GAA0BhD,IAA1B,CAA+Bc,OAAO,IAC3CA,OAAO,CAACC,MAAR,CAAe,CAACuB,GAAD,EAAMW,EAAN,KAAa;AAC1BX,IAAAA,GAAG,CAACW,EAAE,CAACjE,GAAJ,CAAH,GAAciE,EAAd;AACA,WAAOX,GAAP;AACD,GAHD,EAGG,EAHH,CADK,CAAP;AAMD;;AAED,SAASzB,aAAT,CAAwBtB,MAAxB,EAAgC2D,MAAhC,EAAwC;AACtC,SAAO1E,QAAQ,CAACe,MAAD,EAAS,MAAT,CAAR,CAAyBS,IAAzB,CAA+BmD,IAAD,IAAUC,cAAc,CAACD,IAAD,EAAOD,MAAP,CAAtD,CAAP;AACD;;AAED,SAAS/B,iBAAT,CAA4B5B,MAA5B,EAAoC2D,MAApC,EAA4C;AAC1C,QAAMC,IAAI,GAAGtF,EAAE,CAACwF,YAAH,CAAgB9D,MAAhB,EAAwB,MAAxB,CAAb;AACA,SAAO6D,cAAc,CAACD,IAAD,EAAOD,MAAP,CAArB;AACD;;AAED,SAASE,cAAT,CAAyBD,IAAzB,EAA+BD,MAA/B,EAAuC;AACrC,QAAMpC,OAAO,GAAG,EAAhB;AACAqC,EAAAA,IAAI,CAACG,KAAL,CAAW,IAAX,EAAiBC,OAAjB,CAA0B9D,KAAD,IAAW;AAClC,QAAI,CAACA,KAAL,EAAY;AACV;AACD;;AACD,UAAM+D,MAAM,GAAG/D,KAAK,CAAC6D,KAAN,CAAY,IAAZ,CAAf;;AACA,QAAI,CAACE,MAAM,CAAC,CAAD,CAAP,IAAcrD,SAAS,CAACqD,MAAM,CAAC,CAAD,CAAP,CAAT,KAAyBA,MAAM,CAAC,CAAD,CAAjD,EAAsD;AACpD;AACA;AACA;AACD;;AACD,QAAIC,GAAJ;;AACA,QAAI;AACFA,MAAAA,GAAG,GAAGvD,IAAI,CAACwD,KAAL,CAAWF,MAAM,CAAC,CAAD,CAAjB,CAAN;AACD,KAFD,CAEE,OAAOG,CAAP,EAAU;AACV;AACA;AACD;;AACD,QAAIF,GAAJ,EAAS;AACP3C,MAAAA,OAAO,CAAC8C,IAAR,CAAaH,GAAb;AACD;AACF,GApBD;AAqBA,SAAO3C,OAAP;AACD;;AAEDpC,MAAM,CAACC,OAAP,CAAe8C,SAAf,GAA2BA,SAA3B;;AAEA,SAASA,SAAT,CAAoB1C,KAApB,EAA2B;AACzB,SAAOhB,IAAI,CAACkE,IAAL,CAAUlD,KAAV,EAAkB,UAASX,MAAO,EAAlC,CAAP;AACD;;AAEDM,MAAM,CAACC,OAAP,CAAea,UAAf,GAA4BA,UAA5B;;AAEA,SAASA,UAAT,CAAqBT,KAArB,EAA4BC,GAA5B,EAAiC;AAC/B,QAAM6E,MAAM,GAAGC,OAAO,CAAC9E,GAAD,CAAtB;AACA,SAAOjB,IAAI,CAACkE,IAAL,CAAU8B,KAAV,CACLhG,IADK,EAEL,CAAC0D,SAAS,CAAC1C,KAAD,CAAV,EAAmBiF,MAAnB,CAA0B7F,cAAc,CAAC0F,MAAD,CAAxC,CAFK,CAAP;AAID;;AAEDnF,MAAM,CAACC,OAAP,CAAemF,OAAf,GAAyBA,OAAzB;;AAEA,SAASA,OAAT,CAAkB9E,GAAlB,EAAuB;AACrB,SAAOiF,IAAI,CAACjF,GAAD,EAAM,QAAN,CAAX;AACD;;AAEDN,MAAM,CAACC,OAAP,CAAewB,SAAf,GAA2BA,SAA3B;;AAEA,SAASA,SAAT,CAAoB+D,GAApB,EAAyB;AACvB,SAAOD,IAAI,CAACC,GAAD,EAAM,MAAN,CAAX;AACD;;AAED,SAASD,IAAT,CAAeC,GAAf,EAAoBC,MAApB,EAA4B;AAC1B,SAAOvG,MAAM,CACVwG,UADI,CACOD,MADP,EAEJE,MAFI,CAEGH,GAFH,EAGJC,MAHI,CAGG,KAHH,CAAP;AAID;;AAED,SAAS3D,WAAT,CAAsBzB,KAAtB,EAA6BU,KAA7B,EAAoC;AAClC;AACA,MAAI,CAACA,KAAK,CAACN,SAAX,EAAsB;AACpB,WAAO,IAAP;AACD;;AACD,SAAO;AACLH,IAAAA,GAAG,EAAES,KAAK,CAACT,GADN;AAELG,IAAAA,SAAS,EAAEM,KAAK,CAACN,SAFZ;AAGLpB,IAAAA,IAAI,EAAEE,WAAW,CAACc,KAAD,EAAQU,KAAK,CAACN,SAAd,CAHZ;AAILG,IAAAA,IAAI,EAAEG,KAAK,CAACH,IAJP;AAKLK,IAAAA,IAAI,EAAEF,KAAK,CAACE,IALP;AAMLN,IAAAA,QAAQ,EAAEI,KAAK,CAACJ;AANX,GAAP;AAQD;;AAED,SAASuC,cAAT,CAAyB0C,GAAzB,EAA8B;AAC5B,SAAO7F,OAAO,CAAC6F,GAAD,CAAP,CAAajE,KAAb,CAAoBC,GAAD,IAAS;AACjC,QAAIA,GAAG,CAACrB,IAAJ,KAAa,QAAb,IAAyBqB,GAAG,CAACrB,IAAJ,KAAa,SAA1C,EAAqD;AACnD,aAAO,EAAP;AACD;;AAED,UAAMqB,GAAN;AACD,GANM,CAAP;AAOD","sourcesContent":["'use strict'\n\nconst util = require('util')\n\nconst crypto = require('crypto')\nconst fs = require('fs')\nconst Minipass = require('minipass')\nconst path = require('path')\nconst ssri = require('ssri')\nconst contentPath = require('./content/path')\nconst fixOwner = require('./util/fix-owner')\nconst hashToSegments = require('./util/hash-to-segments')\nconst indexV = require('../package.json')['cache-version'].index\n\nconst appendFile = util.promisify(fs.appendFile)\nconst readFile = util.promisify(fs.readFile)\nconst readdir = util.promisify(fs.readdir)\n\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor (cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`)\n    this.code = 'ENOENT'\n    this.cache = cache\n    this.key = key\n  }\n}\n\nmodule.exports.insert = insert\n\nfunction insert (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  }\n  return fixOwner\n    .mkdirfix(cache, path.dirname(bucket))\n    .then(() => {\n      const stringified = JSON.stringify(entry)\n      // NOTE - Cleverness ahoy!\n      //\n      // This works because it's tremendously unlikely for an entry to corrupt\n      // another while still preserving the string length of the JSON in\n      // question. So, we just slap the length in there and verify it on read.\n      //\n      // Thanks to @isaacs for the whiteboarding session that ended up with this.\n      return appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n    })\n    .then(() => fixOwner.chownr(cache, bucket))\n    .catch((err) => {\n      if (err.code === 'ENOENT') {\n        return undefined\n      }\n      throw err\n      // There's a class of race conditions that happen when things get deleted\n      // during fixOwner, or between the two mkdirfix/chownr calls.\n      //\n      // It's perfectly fine to just not bother in those cases and lie\n      // that the index entry was written. Because it's a cache.\n    })\n    .then(() => {\n      return formatEntry(cache, entry)\n    })\n}\n\nmodule.exports.insert.sync = insertSync\n\nfunction insertSync (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  }\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket))\n  const stringified = JSON.stringify(entry)\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n  try {\n    fixOwner.chownr.sync(cache, bucket)\n  } catch (err) {\n    if (err.code !== 'ENOENT') {\n      throw err\n    }\n  }\n  return formatEntry(cache, entry)\n}\n\nmodule.exports.find = find\n\nfunction find (cache, key) {\n  const bucket = bucketPath(cache, key)\n  return bucketEntries(bucket)\n    .then((entries) => {\n      return entries.reduce((latest, next) => {\n        if (next && next.key === key) {\n          return formatEntry(cache, next)\n        } else {\n          return latest\n        }\n      }, null)\n    })\n    .catch((err) => {\n      if (err.code === 'ENOENT') {\n        return null\n      } else {\n        throw err\n      }\n    })\n}\n\nmodule.exports.find.sync = findSync\n\nfunction findSync (cache, key) {\n  const bucket = bucketPath(cache, key)\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next)\n      } else {\n        return latest\n      }\n    }, null)\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null\n    } else {\n      throw err\n    }\n  }\n}\n\nmodule.exports.delete = del\n\nfunction del (cache, key, opts) {\n  return insert(cache, key, null, opts)\n}\n\nmodule.exports.delete.sync = delSync\n\nfunction delSync (cache, key, opts) {\n  return insertSync(cache, key, null, opts)\n}\n\nmodule.exports.lsStream = lsStream\n\nfunction lsStream (cache) {\n  const indexDir = bucketDir(cache)\n  const stream = new Minipass({ objectMode: true })\n\n  readdirOrEmpty(indexDir).then(buckets => Promise.all(\n    buckets.map(bucket => {\n      const bucketPath = path.join(indexDir, bucket)\n      return readdirOrEmpty(bucketPath).then(subbuckets => Promise.all(\n        subbuckets.map(subbucket => {\n          const subbucketPath = path.join(bucketPath, subbucket)\n\n          // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n          return readdirOrEmpty(subbucketPath).then(entries => Promise.all(\n            entries.map(entry => {\n              const entryPath = path.join(subbucketPath, entry)\n              return bucketEntries(entryPath).then(entries =>\n                // using a Map here prevents duplicate keys from\n                // showing up twice, I guess?\n                entries.reduce((acc, entry) => {\n                  acc.set(entry.key, entry)\n                  return acc\n                }, new Map())\n              ).then(reduced => {\n                // reduced is a map of key => entry\n                for (const entry of reduced.values()) {\n                  const formatted = formatEntry(cache, entry)\n                  if (formatted) {\n                    stream.write(formatted)\n                  }\n                }\n              }).catch(err => {\n                if (err.code === 'ENOENT') { return undefined }\n                throw err\n              })\n            })\n          ))\n        })\n      ))\n    })\n  ))\n    .then(\n      () => stream.end(),\n      err => stream.emit('error', err)\n    )\n\n  return stream\n}\n\nmodule.exports.ls = ls\n\nfunction ls (cache) {\n  return lsStream(cache).collect().then(entries =>\n    entries.reduce((acc, xs) => {\n      acc[xs.key] = xs\n      return acc\n    }, {})\n  )\n}\n\nfunction bucketEntries (bucket, filter) {\n  return readFile(bucket, 'utf8').then((data) => _bucketEntries(data, filter))\n}\n\nfunction bucketEntriesSync (bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8')\n  return _bucketEntries(data, filter)\n}\n\nfunction _bucketEntries (data, filter) {\n  const entries = []\n  data.split('\\n').forEach((entry) => {\n    if (!entry) {\n      return\n    }\n    const pieces = entry.split('\\t')\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return\n    }\n    let obj\n    try {\n      obj = JSON.parse(pieces[1])\n    } catch (e) {\n      // Entry is corrupted!\n      return\n    }\n    if (obj) {\n      entries.push(obj)\n    }\n  })\n  return entries\n}\n\nmodule.exports.bucketDir = bucketDir\n\nfunction bucketDir (cache) {\n  return path.join(cache, `index-v${indexV}`)\n}\n\nmodule.exports.bucketPath = bucketPath\n\nfunction bucketPath (cache, key) {\n  const hashed = hashKey(key)\n  return path.join.apply(\n    path,\n    [bucketDir(cache)].concat(hashToSegments(hashed))\n  )\n}\n\nmodule.exports.hashKey = hashKey\n\nfunction hashKey (key) {\n  return hash(key, 'sha256')\n}\n\nmodule.exports.hashEntry = hashEntry\n\nfunction hashEntry (str) {\n  return hash(str, 'sha1')\n}\n\nfunction hash (str, digest) {\n  return crypto\n    .createHash(digest)\n    .update(str)\n    .digest('hex')\n}\n\nfunction formatEntry (cache, entry) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity) {\n    return null\n  }\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: contentPath(cache, entry.integrity),\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  }\n}\n\nfunction readdirOrEmpty (dir) {\n  return readdir(dir).catch((err) => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') {\n      return []\n    }\n\n    throw err\n  })\n}\n"]},"metadata":{},"sourceType":"script"}